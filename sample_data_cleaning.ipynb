{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c12a9c",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4baaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "import contractions\n",
    "import html\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure necessary NLTK data is available\n",
    "for pkg in ['punkt', 'averaged_perceptron_tagger', 'wordnet', 'stopwords']:\n",
    "    nltk.download(pkg, quiet=True)\n",
    "\n",
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb588c1",
   "metadata": {},
   "source": [
    "# Sample Data\n",
    "We subset 20% of the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60bff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv', encoding='utf-8-sig')\n",
    "df_sample = df.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43a9e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir you're my early frontrunner for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir luggage delivery between 1-4am? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>@AmericanAir is rising like the sun at DCA thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue do they have to depart from Washingto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>@JetBlue I can probably find some of them. Are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>@united I would love if someone could get me b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Why did I have to stand at baggag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@united this means within one week i will have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>@SouthwestAir darn! I bought it on the wrong d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  sentiment_confidence  \\\n",
       "4793           positive                1.0000   \n",
       "4802           negative                1.0000   \n",
       "12427          positive                0.6593   \n",
       "8879            neutral                1.0000   \n",
       "8291           negative                0.6625   \n",
       "927             neutral                0.6612   \n",
       "13470          negative                1.0000   \n",
       "2816           negative                1.0000   \n",
       "4504           negative                0.6442   \n",
       "6853            neutral                1.0000   \n",
       "\n",
       "                                                    text  \n",
       "4793   @SouthwestAir you're my early frontrunner for ...  \n",
       "4802   @SouthwestAir luggage delivery between 1-4am? ...  \n",
       "12427  @AmericanAir is rising like the sun at DCA thi...  \n",
       "8879   @JetBlue do they have to depart from Washingto...  \n",
       "8291   @JetBlue I can probably find some of them. Are...  \n",
       "927    @united I would love if someone could get me b...  \n",
       "13470  @AmericanAir Why did I have to stand at baggag...  \n",
       "2816   @united this means within one week i will have...  \n",
       "4504   @SouthwestAir darn! I bought it on the wrong d...  \n",
       "6853   @JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55c322",
   "metadata": {},
   "source": [
    "# Fully Cleaned Sample Data \n",
    "## (Traditional Features Extraction, TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afd1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIONS = {\n",
    "    \"no\",\"nor\",\"not\",\"never\",\"cannot\",\"cant\",\"can't\",\n",
    "    \"do not\",\"does not\",\"did not\",\n",
    "    \"is not\",\"are not\",\"was not\",\"were not\",\n",
    "    \"will not\",\"won't\",\"wont\",\n",
    "    \"would not\",\"should not\",\"could not\",\n",
    "    \"have not\",\"has not\",\"had not\",\n",
    "    \"can not\"  # sometimes appears split\n",
    "}\n",
    "\n",
    "KEEP_SHORT = {\"ok\",\"ugh\",\"wtf\",\"meh\",\"yay\",\"lol\",\"omg\"}\n",
    "KEEP_INTENSIFIERS = {\"very\",\"so\",\"too\",\"really\",\"extremely\",\"quite\",\"super\",\"incredibly\",\"totally\",\"absolutely\"}\n",
    "\n",
    "# Domain stopwords that we want to KEEP (they carry meaning here)\n",
    "PROTECTED_STOPWORDS = {\n",
    "    \"down\",   # wifi down (negative)\n",
    "    \"out\",    # system out / sold out\n",
    "    \"off\",    # turned off / took off\n",
    "    \"up\",     # back up / upgrade\n",
    "    \"back\",   # got back / baggage back\n",
    "    \"over\"    # overbooked\n",
    "}\n",
    "\n",
    "base_stop = set(stopwords.words('english'))\n",
    "# keep negations, intensifiers, and protected domain words\n",
    "custom_stop = {\n",
    "    w for w in base_stop\n",
    "    if (w not in NEGATIONS)\n",
    "    and (w not in KEEP_INTENSIFIERS)\n",
    "    and (w not in PROTECTED_STOPWORDS)\n",
    "}\n",
    "\n",
    "def _to_wordnet_pos(tb_tag):\n",
    "    if tb_tag.startswith('J'): return wordnet.ADJ\n",
    "    if tb_tag.startswith('V'): return wordnet.VERB\n",
    "    if tb_tag.startswith('N'): return wordnet.NOUN\n",
    "    if tb_tag.startswith('R'): return wordnet.ADV\n",
    "    return wordnet.NOUN\n",
    "\n",
    "def clean_tweet(text):\n",
    "    # 1) normalize & basic noise removal (preserve tone signals)\n",
    "    text = contractions.fix(str(text))                         # \"don't\" -> \"do not\"\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))        # ðŸ™‚ -> slightly_smiling_face\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)             # remove URLs\n",
    "    text = re.sub(r'@\\w+', ' ', text)                         # remove mentions\n",
    "    text = text.replace('#', ' ')                             # keep hashtag token\n",
    "    # keep letters, underscores, spaces, and sentiment punctuation ! ?\n",
    "    text = re.sub(r'[^a-z_!\\?\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def protect_negations(text):\n",
    "    \"\"\"\n",
    "    Glue common (expanded + contracted) negations to the next token:\n",
    "    e.g., 'do not like' -> 'do_not_like', 'won't board' -> 'won't_board'\n",
    "    \"\"\"\n",
    "    neg_re = (\n",
    "        r\"(?:no|nor|not|never|cannot|cant|can't|\"\n",
    "        r\"do not|does not|did not|is not|are not|was not|were not|\"\n",
    "        r\"will not|won't|wont|would not|should not|could not|\"\n",
    "        r\"have not|has not|had not|can not)\"\n",
    "    )\n",
    "    # replace spaces inside [NEGATION + next_token] span with underscores\n",
    "    def repl(m): return m.group(0).replace(' ', '_')\n",
    "    return re.sub(rf\"\\b{neg_re}\\s+[a-z_]+\", repl, text)\n",
    "\n",
    "def pos_lemmatize_with_stop(text):\n",
    "    \"\"\"\n",
    "    Keep negations/emoji tokens; keep intensifiers and short emotion tokens;\n",
    "    lemmatize nouns/verbs; avoid lemmatizing ADJ/ADV to preserve tone.\n",
    "    \"\"\"\n",
    "    toks = word_tokenize(text)\n",
    "    kept = []\n",
    "    for t in toks:\n",
    "        if t in NEGATIONS or '_' in t:                  # glued negations & emoji words\n",
    "            kept.append(t)\n",
    "        elif t in KEEP_SHORT or t in KEEP_INTENSIFIERS:\n",
    "            kept.append(t)\n",
    "        elif t in custom_stop:\n",
    "            continue\n",
    "        else:\n",
    "            kept.append(t)\n",
    "\n",
    "    tagged = pos_tag(kept)\n",
    "    lemmas = []\n",
    "    for w, tag in tagged:\n",
    "        if tag.startswith('J') or tag.startswith('R'):  # keep adjectives/adverbs as-is\n",
    "            lemmas.append(w)\n",
    "        else:\n",
    "            lemmas.append(lemmatizer.lemmatize(w, _to_wordnet_pos(tag)))\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "def clean_pipeline(text):\n",
    "    text = clean_tweet(text)\n",
    "    text = protect_negations(text)\n",
    "    text = pos_lemmatize_with_stop(text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69854c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_sample = df_sample.copy()\n",
    "df_cleaned_sample['clean_text'] = df_cleaned_sample['text'].apply(clean_pipeline)\n",
    "df_cleaned_sample.to_csv('cleaned_sample_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1513c1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir you're my early frontrunner for ...</td>\n",
       "      <td>early frontrunner best airline ! oscar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir luggage delivery between 1-4am? ...</td>\n",
       "      <td>luggage delivery ? really ? tell midnight mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>@AmericanAir is rising like the sun at DCA thi...</td>\n",
       "      <td>rise like sun dca morning member best view avgeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue do they have to depart from Washingto...</td>\n",
       "      <td>depart washington c ? ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>@JetBlue I can probably find some of them. Are...</td>\n",
       "      <td>probably find ticket ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>@united I would love if someone could get me b...</td>\n",
       "      <td>would love someone could get back austin tonig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Why did I have to stand at baggag...</td>\n",
       "      <td>stand baggage claim hour wait bag know never_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@united this means within one week i will have...</td>\n",
       "      <td>mean within one week file compensation complai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>@SouthwestAir darn! I bought it on the wrong d...</td>\n",
       "      <td>darn ! buy wrong device ! no_way switch sure ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...</td>\n",
       "      <td>flight n jb jblu arrive follow flight westches...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  sentiment_confidence  \\\n",
       "4793           positive                1.0000   \n",
       "4802           negative                1.0000   \n",
       "12427          positive                0.6593   \n",
       "8879            neutral                1.0000   \n",
       "8291           negative                0.6625   \n",
       "927             neutral                0.6612   \n",
       "13470          negative                1.0000   \n",
       "2816           negative                1.0000   \n",
       "4504           negative                0.6442   \n",
       "6853            neutral                1.0000   \n",
       "\n",
       "                                                    text  \\\n",
       "4793   @SouthwestAir you're my early frontrunner for ...   \n",
       "4802   @SouthwestAir luggage delivery between 1-4am? ...   \n",
       "12427  @AmericanAir is rising like the sun at DCA thi...   \n",
       "8879   @JetBlue do they have to depart from Washingto...   \n",
       "8291   @JetBlue I can probably find some of them. Are...   \n",
       "927    @united I would love if someone could get me b...   \n",
       "13470  @AmericanAir Why did I have to stand at baggag...   \n",
       "2816   @united this means within one week i will have...   \n",
       "4504   @SouthwestAir darn! I bought it on the wrong d...   \n",
       "6853   @JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...   \n",
       "\n",
       "                                              clean_text  \n",
       "4793              early frontrunner best airline ! oscar  \n",
       "4802   luggage delivery ? really ? tell midnight mult...  \n",
       "12427  rise like sun dca morning member best view avgeek  \n",
       "8879                             depart washington c ? ?  \n",
       "8291                              probably find ticket ?  \n",
       "927    would love someone could get back austin tonig...  \n",
       "13470  stand baggage claim hour wait bag know never_m...  \n",
       "2816   mean within one week file compensation complai...  \n",
       "4504      darn ! buy wrong device ! no_way switch sure ?  \n",
       "6853   flight n jb jblu arrive follow flight westches...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c435a82",
   "metadata": {},
   "source": [
    "# Minimally Cleaned Sample Data\n",
    "## (GloVe, SBERT, BERTweet, CardiffNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a5ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_clean_pipeline(text):\n",
    "    text = html.unescape(text)             # Decode &amp;, &gt;, etc.\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)    # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)       # Remove mentions\n",
    "    text = re.sub(r\"\\s+\", \" \", text)       # Normalize whitespace\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb224dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_cleaned_sample = df_sample.copy()\n",
    "df_min_cleaned_sample['clean_text'] = df_min_cleaned_sample['text'].apply(min_clean_pipeline)\n",
    "df_min_cleaned_sample.to_csv('min_cleaned_sample_tweets.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1b25b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir you're my early frontrunner for ...</td>\n",
       "      <td>you're my early frontrunner for best airline! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@SouthwestAir luggage delivery between 1-4am? ...</td>\n",
       "      <td>luggage delivery between 1-4am? Really? After ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>@AmericanAir is rising like the sun at DCA thi...</td>\n",
       "      <td>is rising like the sun at DCA this morning. me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue do they have to depart from Washingto...</td>\n",
       "      <td>do they have to depart from Washington, D.C.??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>@JetBlue I can probably find some of them. Are...</td>\n",
       "      <td>I can probably find some of them. Are the tick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>@united I would love if someone could get me b...</td>\n",
       "      <td>I would love if someone could get me back to A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13470</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Why did I have to stand at baggag...</td>\n",
       "      <td>Why did I have to stand at baggage claim for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@united this means within one week i will have...</td>\n",
       "      <td>this means within one week i will have filed 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>@SouthwestAir darn! I bought it on the wrong d...</td>\n",
       "      <td>darn! I bought it on the wrong device! No way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...</td>\n",
       "      <td>Flight 1447 (N351JB) \"JBLU\" arrives at followi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  sentiment_confidence  \\\n",
       "4793           positive                1.0000   \n",
       "4802           negative                1.0000   \n",
       "12427          positive                0.6593   \n",
       "8879            neutral                1.0000   \n",
       "8291           negative                0.6625   \n",
       "927             neutral                0.6612   \n",
       "13470          negative                1.0000   \n",
       "2816           negative                1.0000   \n",
       "4504           negative                0.6442   \n",
       "6853            neutral                1.0000   \n",
       "\n",
       "                                                    text  \\\n",
       "4793   @SouthwestAir you're my early frontrunner for ...   \n",
       "4802   @SouthwestAir luggage delivery between 1-4am? ...   \n",
       "12427  @AmericanAir is rising like the sun at DCA thi...   \n",
       "8879   @JetBlue do they have to depart from Washingto...   \n",
       "8291   @JetBlue I can probably find some of them. Are...   \n",
       "927    @united I would love if someone could get me b...   \n",
       "13470  @AmericanAir Why did I have to stand at baggag...   \n",
       "2816   @united this means within one week i will have...   \n",
       "4504   @SouthwestAir darn! I bought it on the wrong d...   \n",
       "6853   @JetBlue Flight 1447 (N351JB) \"JBLU\" arrives a...   \n",
       "\n",
       "                                              clean_text  \n",
       "4793   you're my early frontrunner for best airline! ...  \n",
       "4802   luggage delivery between 1-4am? Really? After ...  \n",
       "12427  is rising like the sun at DCA this morning. me...  \n",
       "8879      do they have to depart from Washington, D.C.??  \n",
       "8291   I can probably find some of them. Are the tick...  \n",
       "927    I would love if someone could get me back to A...  \n",
       "13470  Why did I have to stand at baggage claim for a...  \n",
       "2816   this means within one week i will have filed 2...  \n",
       "4504   darn! I bought it on the wrong device! No way ...  \n",
       "6853   Flight 1447 (N351JB) \"JBLU\" arrives at followi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_cleaned_sample.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
