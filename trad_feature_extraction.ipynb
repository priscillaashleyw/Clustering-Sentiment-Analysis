{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936e00f5",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3c1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, normalize, LabelEncoder\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import re, emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e80019",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4199df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(\"cleaned_tweets.csv\")\n",
    "texts = df_cleaned[\"clean_text\"].astype(str).tolist()\n",
    "\n",
    "df_cleaned_sample = pd.read_csv(\"cleaned_sample_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b5790",
   "metadata": {},
   "source": [
    "# Traditional Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab2aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature set: v1 (no DR) ===\n",
      "\n",
      "=== Feature set: v2 (no DR) ===\n",
      "\n",
      "================ Tuning (20% subset): all parameters & silhouette ================\n",
      "Feature_Set Reducer  Model     Param  Silhouette\n",
      "         v1    None  Agglo   average    0.344664\n",
      "         v1    None  Agglo  complete    0.344080\n",
      "         v1    None  Agglo    single   -0.090795\n",
      "         v1    None    GMM      diag    0.212222\n",
      "         v1    None    GMM      full    0.195763\n",
      "         v1    None    GMM      tied    0.191331\n",
      "         v1    None    GMM spherical    0.156560\n",
      "         v1    None KMeans         -    0.393412\n",
      "         v2    None  Agglo   average    0.329216\n",
      "         v2    None  Agglo  complete    0.308838\n",
      "         v2    None  Agglo    single   -0.138342\n",
      "         v2    None    GMM      tied    0.232809\n",
      "         v2    None    GMM      diag    0.186877\n",
      "         v2    None    GMM spherical    0.136919\n",
      "         v2    None    GMM      full    0.119088\n",
      "         v2    None KMeans         -    0.376471\n",
      "\n",
      "================ Best Parameters per Branch (20% subset) ================\n",
      "Feature_Set Reducer  Model Best_Param  Best_Silhouette\n",
      "         v1    None  Agglo    average         0.344664\n",
      "         v1    None    GMM       diag         0.212222\n",
      "         v1    None KMeans          -         0.393412\n",
      "         v2    None  Agglo    average         0.329216\n",
      "         v2    None    GMM       tied         0.232809\n",
      "         v2    None KMeans          -         0.376471\n",
      "\n",
      "================ Final Evaluation on Full Cleaned Data (All 6 best models) ================\n",
      "Feature_Set Reducer  Model   Param  Silhouette      ARI      NMI  Hungarian\n",
      "         v1    None  Agglo average    0.336990 0.093929 0.113672   0.530227\n",
      "         v1    None    GMM    diag    0.203930 0.070057 0.075102   0.545939\n",
      "         v1    None KMeans       -    0.386267 0.069908 0.138275   0.512535\n",
      "         v2    None  Agglo average    0.339829 0.109256 0.152754   0.545256\n",
      "         v2    None    GMM    tied    0.241526 0.108313 0.155872   0.534189\n",
      "         v2    None KMeans       -    0.383894 0.119040 0.159973   0.549696\n",
      "\n",
      "Winner by Silhouette: v1+KMeans | Silhouette=0.386 | -\n",
      "\n",
      "Winner by ARI: v2+KMeans | ARI=0.119 | -\n",
      "\n",
      "Winner by NMI: v2+KMeans | NMI=0.160 | -\n",
      "\n",
      "Winner by Hungarian: v2+KMeans | Hungarian=0.550 | -\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Helpers: features + metrics\n",
    "# -------------------------------\n",
    "def _count_emojis(s: str) -> int:\n",
    "    return sum(ch in emoji.EMOJI_DATA for ch in s)\n",
    "\n",
    "def _safe_ratio(num, den):\n",
    "    den = den if den > 0 else 1\n",
    "    return float(num) / float(den)\n",
    "\n",
    "_DEFAULT_POS = {\"good\",\"great\",\"amazing\",\"love\",\"loved\",\"awesome\",\"thanks\",\"thank\",\"best\",\"upgrade\",\"nice\",\"happy\"}\n",
    "_DEFAULT_NEG = {\"bad\",\"worst\",\"delay\",\"delayed\",\"late\",\"hate\",\"horrible\",\"terrible\",\"lost\",\"cancel\",\"canceled\",\"cancellation\",\"angry\",\"sad\"}\n",
    "\n",
    "def extract_features(texts, version=\"v1\", pos_lex=None, neg_lex=None):\n",
    "    \"\"\"\n",
    "    v1 = [\"word_count\",\"avg_word_len\",\"exclam_count\",\"ques_count\",\"upper_count\",\"emoji_count\",\"vader_compound\"]\n",
    "    v2 = v1 + [\"exclam_ratio\",\"ques_ratio\",\"vader_pos\",\"vader_neu\",\"vader_neg\",\"pos_lex_cnt\",\"neg_lex_cnt\",\"neg_pos_lex_ratio\"]\n",
    "    \"\"\"\n",
    "    if pos_lex is None: pos_lex = _DEFAULT_POS\n",
    "    if neg_lex is None: neg_lex = _DEFAULT_NEG\n",
    "    feats = []\n",
    "    for s in texts:\n",
    "        s = s if isinstance(s, str) else str(s)\n",
    "        s_strip = s.strip()\n",
    "\n",
    "        exclam_count = s_strip.count('!')\n",
    "        ques_count   = s_strip.count('?')\n",
    "        emoji_count  = _count_emojis(s_strip)\n",
    "\n",
    "        tokens = s_strip.split()\n",
    "        word_count = sum(1 for t in tokens if any(ch.isalpha() for ch in t))\n",
    "        alpha_tokens = [''.join(ch for ch in t if ch.isalpha()) for t in tokens if any(ch.isalpha() for ch in t)]\n",
    "        avg_word_len = (sum(len(t) for t in alpha_tokens) / len(alpha_tokens)) if alpha_tokens else 0.0\n",
    "        upper_count  = sum(1 for t in tokens if t.isupper() and len(t) >= 2)\n",
    "\n",
    "        vs = _analyzer.polarity_scores(s_strip)\n",
    "        vader_pos, vader_neu, vader_neg, vader_compound = vs[\"pos\"], vs[\"neu\"], vs[\"neg\"], vs[\"compound\"]\n",
    "\n",
    "        exclam_ratio = _safe_ratio(exclam_count, word_count)\n",
    "        ques_ratio   = _safe_ratio(ques_count, word_count)\n",
    "\n",
    "        lowered = [re.sub(r'^\\W+|\\W+$', '', t.lower()) for t in tokens]\n",
    "        pos_lex_cnt = sum(1 for t in lowered if t in pos_lex)\n",
    "        neg_lex_cnt = sum(1 for t in lowered if t in neg_lex)\n",
    "        neg_pos_lex_ratio = _safe_ratio(neg_lex_cnt, pos_lex_cnt)\n",
    "\n",
    "        row_v1 = [float(word_count), float(avg_word_len), float(exclam_count),\n",
    "                  float(ques_count), float(upper_count), float(emoji_count), float(vader_compound)]\n",
    "\n",
    "        if version == \"v1\":\n",
    "            feats.append(row_v1)\n",
    "        elif version == \"v2\":\n",
    "            row_v2 = row_v1 + [float(exclam_ratio), float(ques_ratio),\n",
    "                               float(vader_pos), float(vader_neu), float(vader_neg),\n",
    "                               float(pos_lex_cnt), float(neg_lex_cnt), float(neg_pos_lex_ratio)]\n",
    "            feats.append(row_v2)\n",
    "        else:\n",
    "            raise ValueError(\"version must be 'v1' or 'v2'\")\n",
    "    return np.asarray(feats, dtype=np.float32)\n",
    "\n",
    "def clustering_accuracy(y_true_int, y_pred_int):\n",
    "    cm = confusion_matrix(y_true_int, y_pred_int)\n",
    "    r, c = linear_sum_assignment(-cm)\n",
    "    return cm[r, c].sum() / cm.sum()\n",
    "\n",
    "def evaluate_all(X, y_true_int, labels, sil_metric):\n",
    "    sil = silhouette_score(X, labels, metric=sil_metric)\n",
    "    ari = adjusted_rand_score(y_true_int, labels)\n",
    "    nmi = normalized_mutual_info_score(y_true_int, labels)\n",
    "    acc = clustering_accuracy(y_true_int, labels)\n",
    "    return sil, ari, nmi, acc\n",
    "\n",
    "# --------------------------------------\n",
    "# Data + label encoding (stable mapping)\n",
    "# --------------------------------------\n",
    "texts_sample = df_cleaned_sample[\"clean_text\"].astype(str).tolist()\n",
    "texts_full   = df_cleaned[\"clean_text\"].astype(str).tolist()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_cleaned[\"airline_sentiment\"].astype(str))\n",
    "y_sample_enc = le.transform(df_cleaned_sample[\"airline_sentiment\"].astype(str))\n",
    "y_full_enc   = le.transform(df_cleaned[\"airline_sentiment\"].astype(str))\n",
    "\n",
    "# --------------------\n",
    "# Configs \n",
    "# --------------------\n",
    "feature_versions = [\"v1\", \"v2\"]\n",
    "gmm_cov_types    = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "agg_linkages     = [\"average\", \"complete\", \"single\"]\n",
    "\n",
    "# results containers\n",
    "df_tuning_rows = []   # subset (silhouette only)\n",
    "df_best_rows   = []   # best per model per feature set\n",
    "df_final_rows  = []   # full data with all metrics\n",
    "\n",
    "# -------------\n",
    "# Main routine \n",
    "# -------------\n",
    "for version in feature_versions:\n",
    "    print(f\"\\n=== Feature set: {version} (no DR) ===\")\n",
    "\n",
    "    # features\n",
    "    Xs = extract_features(texts_sample, version=version)\n",
    "    Xf = extract_features(texts_full,   version=version)\n",
    "\n",
    "    # standardize and make cosine-friendly\n",
    "    scaler_s = StandardScaler().fit(Xs)\n",
    "    Xs_std   = scaler_s.transform(Xs).astype(np.float64)\n",
    "    Xs_l2    = normalize(Xs_std, norm=\"l2\")\n",
    "\n",
    "    scaler_f = StandardScaler().fit(Xf)\n",
    "    Xf_std   = scaler_f.transform(Xf).astype(np.float64)\n",
    "    Xf_l2    = normalize(Xf_std, norm=\"l2\")\n",
    "\n",
    "    # ---------- KMEANS (fixed) ----------\n",
    "    kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "    lab_s  = kmeans.fit_predict(Xs_l2)\n",
    "    sil_s  = silhouette_score(Xs_l2, lab_s, metric=\"cosine\")\n",
    "    df_tuning_rows.append([version, \"None\", \"KMeans\", \"-\", sil_s])\n",
    "    df_best_rows.append([version, \"None\", \"KMeans\", \"-\", sil_s])\n",
    "\n",
    "    # ---------- GMM (tune covariance_type) ----------\n",
    "    best_gmm = (None, -np.inf)\n",
    "    for cov in gmm_cov_types:\n",
    "        gmm   = GaussianMixture(n_components=3, n_init=10, random_state=42, covariance_type=cov)\n",
    "        lab_s = gmm.fit_predict(Xs_std)  # euclidean after std\n",
    "        sil_s = silhouette_score(Xs_std, lab_s, metric=\"euclidean\")\n",
    "        df_tuning_rows.append([version, \"None\", \"GMM\", cov, sil_s])\n",
    "        if sil_s > best_gmm[1]:\n",
    "            best_gmm = (cov, sil_s)\n",
    "    df_best_rows.append([version, \"None\", \"GMM\", best_gmm[0], best_gmm[1]])\n",
    "\n",
    "    # ---------- AGGLO (tune linkage; cosine) ----------\n",
    "    def _agglo(metric_or_affinity, linkage, n_clusters=3):\n",
    "        try:\n",
    "            return AgglomerativeClustering(n_clusters=n_clusters, metric=metric_or_affinity, linkage=linkage)\n",
    "        except TypeError:  # sklearn<1.2\n",
    "            return AgglomerativeClustering(n_clusters=n_clusters, affinity=metric_or_affinity, linkage=linkage)\n",
    "\n",
    "    best_agg = (None, -np.inf)\n",
    "    for link in agg_linkages:\n",
    "        agg   = _agglo(\"cosine\", link, n_clusters=3)\n",
    "        lab_s = agg.fit_predict(Xs_l2)\n",
    "        sil_s = silhouette_score(Xs_l2, lab_s, metric=\"cosine\")\n",
    "        df_tuning_rows.append([version, \"None\", \"Agglo\", link, sil_s])\n",
    "        if sil_s > best_agg[1]:\n",
    "            best_agg = (link, sil_s)\n",
    "    df_best_rows.append([version, \"None\", \"Agglo\", best_agg[0], best_agg[1]])\n",
    "\n",
    "    # =========================\n",
    "    # FINAL EVAL ON FULL DATA\n",
    "    # =========================\n",
    "    # KMeans\n",
    "    kmeans_full = KMeans(n_clusters=3, n_init=10, random_state=42).fit(Xf_l2)\n",
    "    lab_f = kmeans_full.labels_\n",
    "    sil, ari, nmi, acc = evaluate_all(Xf_l2, y_full_enc, lab_f, sil_metric=\"cosine\")\n",
    "    df_final_rows.append([version, \"None\", \"KMeans\", \"-\", sil, ari, nmi, acc])\n",
    "\n",
    "    # GMM\n",
    "    gmm_full = GaussianMixture(n_components=3, n_init=10, random_state=42,\n",
    "                               covariance_type=best_gmm[0]).fit(Xf_std)\n",
    "    lab_f = gmm_full.predict(Xf_std)\n",
    "    sil, ari, nmi, acc = evaluate_all(Xf_std, y_full_enc, lab_f, sil_metric=\"euclidean\")\n",
    "    df_final_rows.append([version, \"None\", \"GMM\", best_gmm[0], sil, ari, nmi, acc])\n",
    "\n",
    "    # Agglo\n",
    "    agg_full = _agglo(\"cosine\", best_agg[0], n_clusters=3).fit(Xf_l2)\n",
    "    lab_f = agg_full.labels_\n",
    "    sil, ari, nmi, acc = evaluate_all(Xf_l2, y_full_enc, lab_f, sil_metric=\"cosine\")\n",
    "    df_final_rows.append([version, \"None\", \"Agglo\", best_agg[0], sil, ari, nmi, acc])\n",
    "\n",
    "# ------------------------\n",
    "# TABLES \n",
    "# ------------------------\n",
    "df_tuning = pd.DataFrame(df_tuning_rows, columns=[\"Feature_Set\",\"Reducer\",\"Model\",\"Param\",\"Silhouette\"])\n",
    "df_best   = pd.DataFrame(df_best_rows,   columns=[\"Feature_Set\",\"Reducer\",\"Model\",\"Best_Param\",\"Best_Silhouette\"])\n",
    "df_final  = pd.DataFrame(df_final_rows,  columns=[\"Feature_Set\",\"Reducer\",\"Model\",\"Param\",\"Silhouette\",\"ARI\",\"NMI\",\"Hungarian\"])\n",
    "\n",
    "print(\"\\n================ Tuning (20% subset): all parameters & silhouette ================\")\n",
    "print(df_tuning.sort_values([\"Feature_Set\",\"Reducer\",\"Model\",\"Silhouette\"], ascending=[True, True, True, False]).to_string(index=False))\n",
    "\n",
    "print(\"\\n================ Best Parameters per Branch (20% subset) ================\")\n",
    "print(df_best.sort_values([\"Feature_Set\",\"Reducer\",\"Model\"]).to_string(index=False))\n",
    "\n",
    "print(\"\\n================ Final Evaluation on Full Cleaned Data (All 6 best models) ================\")\n",
    "print(df_final.sort_values([\"Feature_Set\",\"Reducer\",\"Model\"]).to_string(index=False))\n",
    "\n",
    "# ==========================================================\n",
    "# Quick metric winners\n",
    "# ==========================================================\n",
    "for metric in [\"Silhouette\",\"ARI\",\"NMI\",\"Hungarian\"]:\n",
    "    r = df_final.loc[df_final[metric].idxmax()]\n",
    "    print(f\"\\nWinner by {metric}: {r[\"Feature_Set\"]}+{r[\"Model\"]} | {metric}={r[metric]:.3f} | {r[\"Param\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
